#!/bin/bash
# æåº¦ä¿å®ˆçš„è®­ç»ƒå¯åŠ¨ - é€æ­¥åŠ è½½ä»¥é¿å…å´©æºƒ

set -e

CONFIG="configs/rtdetr/rtdetr_r50vd_coco_indoor_4k.yml"
OUTPUT_DIR="/home/cui/rtdetr_indoor/output/rtdetr_r50vd_coco_indoor_4k"
CHECKPOINT="$OUTPUT_DIR/checkpoint.pth"

source ~/miniconda3/etc/profile.d/conda.sh
conda activate rtdetr
cd /home/cui/rtdetr_indoor/RT-DETR/rtdetr_pytorch

echo "=========================================="
echo "ğŸ¢ æåº¦ä¿å®ˆæ¨¡å¼è®­ç»ƒå¯åŠ¨"
echo "=========================================="

# æ­¥éª¤1: GPUé¢„çƒ­ï¼ˆé¿å…å†·å¯åŠ¨å†²å‡»ï¼‰
echo -e "\nğŸ”¥ æ­¥éª¤1: GPUé¢„çƒ­ï¼ˆ5ç§’ï¼‰..."
python << 'EOF'
import torch
import time
model = torch.nn.Linear(100, 100).cuda()
for i in range(3):
    x = torch.randn(10, 100).cuda()
    y = model(x)
    time.sleep(1)
    print(f"  é¢„çƒ­ {i+1}/3")
del model, x, y
torch.cuda.empty_cache()
print("âœ… é¢„çƒ­å®Œæˆ")
EOF

sleep 2

# æ­¥éª¤2: ç­‰å¾…GPUæ¸©åº¦ç¨³å®š
echo -e "\nğŸŒ¡ï¸  æ­¥éª¤2: ç­‰å¾…GPUæ¸©åº¦ç¨³å®šï¼ˆ3ç§’ï¼‰..."
sleep 3
TEMP=$(nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader)
echo "  å½“å‰GPUæ¸©åº¦: ${TEMP}Â°C"

# æ­¥éª¤3: æ£€æŸ¥æ£€æŸ¥ç‚¹
if [ -f "$CHECKPOINT" ]; then
    echo -e "\nğŸ’¾ æ­¥éª¤3: å‘ç°æ£€æŸ¥ç‚¹ï¼Œå°†ä»ä¸Šæ¬¡æ¢å¤"
    RESUME_FLAG="--resume $CHECKPOINT"
else
    echo -e "\nğŸ†• æ­¥éª¤3: ä»å¤´å¼€å§‹è®­ç»ƒ"
    RESUME_FLAG=""
fi

# æ­¥éª¤4: é€æ­¥å¯åŠ¨è®­ç»ƒ
echo -e "\nğŸš€ æ­¥éª¤4: å¯åŠ¨è®­ç»ƒ..."
echo "=========================================="
echo "âš™ï¸  é…ç½®: batch_size=4, num_workers=2"
echo "âš™ï¸  æ··åˆç²¾åº¦: å¯ç”¨"
echo "âš™ï¸  Epochs: 100"
echo "=========================================="

sleep 1

# å¯åŠ¨è®­ç»ƒ
python tools/train.py \
    -c $CONFIG \
    $RESUME_FLAG \
    --amp \
    --seed 42

echo -e "\n=========================================="
echo "è®­ç»ƒç»“æŸæˆ–ä¸­æ–­"
echo "=========================================="
