# -*- coding: utf-8 -*-
"""
åŸºäºViLDçš„å¼€æ”¾ä¸–ç•Œå®¤å†…ç‰©ä½“æ£€æµ‹ - åœºæ™¯åˆ†ç±»å™¨æ¨¡å—
"""

import os
import torch
import torch.nn.functional as F
import numpy as np
from PIL import Image
import time
import clip

class SceneClassifier:
    """åœºæ™¯åˆ†ç±»å™¨ï¼Œç”¨äºè¯†åˆ«å®¤å†…åœºæ™¯ç±»å‹"""
    
    def __init__(self, clip_model, clip_preprocess=None, device="cuda"):
        """åˆå§‹åŒ–åœºæ™¯åˆ†ç±»å™¨"""
        self.clip_model = clip_model
        self.clip_preprocess = clip_preprocess
        self.device = device
        
        # åœºæ™¯ç±»åˆ«å®šä¹‰ï¼ˆæ·»åŠ æ›´å¤šåœºæ™¯ç±»å‹ï¼‰
        self.scene_types = [
            "bathroom", "bedroom", "kitchen", "living room", 
            "dining room", "office", "hallway", "laundry room",
            "person", "portrait", "selfie",  # äººç‰©ç›¸å…³åœºæ™¯
            "food", "meal", "dish", "cuisine",  # é£Ÿç‰©ç›¸å…³åœºæ™¯
            "restaurant", "cafe", "tableware",  # é¤é¥®åœºæ‰€
            "cat", "dog", "pet", "animal"  # åŠ¨ç‰©ç›¸å…³åœºæ™¯
        ]
        
        # åœºæ™¯æè¿°æ¨¡æ¿
        self.scene_templates = [
            "a {}", "an indoor {}", "a typical {}", 
            "a photo of a {}", "a picture of a {}"
        ]
        
        # ç¼“å­˜åœºæ™¯æ–‡æœ¬ç‰¹å¾
        self._cache_scene_features()
        
        print("âœ… åœºæ™¯åˆ†ç±»å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _cache_scene_features(self):
        """ç¼“å­˜åœºæ™¯æ–‡æœ¬ç‰¹å¾"""
        all_features = []
        
        for scene in self.scene_types:
            scene_features = []
            
            for template in self.scene_templates:
                text = template.format(scene)
                tokens = clip.tokenize([text]).to(self.device)
                
                with torch.no_grad():
                    features = self.clip_model.encode_text(tokens)
                    normalized = F.normalize(features, p=2, dim=1)
                    scene_features.append(normalized)
            
            # å¹³å‡æ‰€æœ‰æ¨¡æ¿çš„ç‰¹å¾
            scene_avg = torch.cat(scene_features).mean(dim=0, keepdim=True)
            all_features.append(scene_avg)
        
        # åˆå¹¶æ‰€æœ‰åœºæ™¯ç‰¹å¾
        self.scene_text_features = torch.cat(all_features, dim=0)
    
    def classify_scene(self, image_path, top_k=1):
        """åˆ†ç±»å›¾åƒåœºæ™¯ç±»å‹"""
        try:
            start_time = time.time()
            
            # æ‰“å¼€å›¾åƒ
            if isinstance(image_path, str):
                image = Image.open(image_path).convert("RGB")
            else:
                image = image_path  # å‡è®¾å·²ç»æ˜¯PILå›¾åƒ
            
            # é¢„å¤„ç†å›¾åƒ
            image_input = self.clip_preprocess(image).unsqueeze(0).to(self.device)
            
            # æå–å›¾åƒç‰¹å¾
            with torch.no_grad():
                image_features = self.clip_model.encode_image(image_input)
                image_features = F.normalize(image_features, p=2, dim=1)
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = torch.mm(image_features, self.scene_text_features.t())
            
            # è·å–ç»“æœ
            values, indices = similarity.topk(min(top_k, len(self.scene_types)))
            
            results = []
            for i in range(values.size(1)):
                score = values[0][i].item()
                scene_idx = indices[0][i].item()
                scene_type = self.scene_types[scene_idx]
                results.append((scene_type, score))
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            if top_k == 1:
                print(f"ğŸ  åœºæ™¯è¯†åˆ«ç»“æœ: {results[0][0]} (ç½®ä¿¡åº¦: {results[0][1]:.3f}, ç”¨æ—¶: {processing_time:.2f}ç§’)")
                return results[0][0], results[0][1]
            else:
                print(f"ğŸ  åœºæ™¯è¯†åˆ«ç»“æœ:")
                for scene, score in results:
                    print(f"   - {scene}: {score:.3f}")
                print(f"â±ï¸ åœºæ™¯è¯†åˆ«ç”¨æ—¶: {processing_time:.2f}ç§’")
                return results
                
        except Exception as e:
            import traceback
            print(f"âŒ åœºæ™¯åˆ†ç±»å¤±è´¥: {e}")
            traceback.print_exc()
            return None, 0.0
    
    def get_scene_type(self, scene_name):
        """å°†åœºæ™¯åç§°æ˜ å°„åˆ°ç±»å‹"""
        # åœºæ™¯ç±»å‹æ˜ å°„
        scene_mapping = {
            # æµ´å®¤ç›¸å…³
            "bathroom": "bathroom",
            "washroom": "bathroom",
            "toilet": "bathroom",
            "powder room": "bathroom",
            "shower room": "bathroom",
            
            # å§å®¤ç›¸å…³
            "bedroom": "bedroom",
            "master bedroom": "bedroom",
            "children room": "bedroom",
            "guest room": "bedroom",
            
            # å¨æˆ¿ç›¸å…³
            "kitchen": "kitchen",
            "kitchenette": "kitchen",
            
            # å®¢å…ç›¸å…³
            "living room": "living_room",
            "lounge": "living_room",
            "family room": "living_room",
            "sitting room": "living_room",
            
            # é¤å…ç›¸å…³
            "dining room": "dining_room",
            
            # åŠå…¬å®¤ç›¸å…³
            "office": "office",
            "study room": "office",
            "home office": "office",
            "computer room": "office",
            
            # èµ°å»Šç›¸å…³
            "hallway": "hallway",
            "corridor": "hallway",
            "entrance": "hallway",
            
            # æ´—è¡£æˆ¿ç›¸å…³
            "laundry room": "laundry_room",
            "utility room": "laundry_room",
            
            # äººç‰©ç›¸å…³
            "person": "person",
            "portrait": "person",
            "selfie": "person",
            "people": "person",
            "human": "person",
            
            # é£Ÿç‰©ç›¸å…³ï¼ˆæ–°å¢ï¼‰
            "food": "food",
            "meal": "food",
            "dish": "food",
            "cuisine": "food",
            "plate": "food",
            "dinner": "food",
            "lunch": "food",
            "breakfast": "food",
            "restaurant": "food",
            "cafe": "food",
            "tableware": "food",
            
            # åŠ¨ç‰©ç›¸å…³åœºæ™¯
            "cat": "animal",
            "dog": "animal",
            "pet": "animal",
            "animal": "animal",
            "kitten": "animal",
            "puppy": "animal",
            "kitty": "animal",
            "feline": "animal",
            "canine": "animal",
        }
        
        # è½¬æ¢ä¸ºå°å†™å¹¶å°è¯•åŒ¹é…
        scene_lower = scene_name.lower().strip()
        if scene_lower in scene_mapping:
            return scene_mapping[scene_lower]
        
        # éƒ¨åˆ†åŒ¹é…
        for key, value in scene_mapping.items():
            if key in scene_lower or scene_lower in key:
                return value
        
        # é»˜è®¤è¿”å›Noneè¡¨ç¤ºæœªçŸ¥åœºæ™¯
        return None
