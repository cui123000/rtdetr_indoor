#!/usr/bin/env python3
"""
ä»COCOåŸå§‹æ•°æ®é›†ä¸­ç­›é€‰HomeObjectsæ‰©å±•ç±»åˆ«ï¼Œä¸¥æ ¼æ’é™¤å®¤å¤–åœºæ™¯
ä½¿ç”¨Places365è¿›è¡Œå®¤å†…/å®¤å¤–åˆ†ç±»
"""

import os
import shutil
import json
import torch
import torch.nn as nn
from pathlib import Path
from tqdm import tqdm
import yaml
from PIL import Image
import torchvision.transforms as transforms
import numpy as np

# HomeObjectsæ ¸å¿ƒç±»åˆ« + æ‰©å……çš„å®¶å…·ã€ç”µå™¨ã€å®¶å±…ç”¨å“
COCO_TO_HOMEOBJECTS_EXTENDED = {
    # === HomeObjectsæ ¸å¿ƒç±»åˆ« ===
    # æ ¸å¿ƒå®¶å…· (0-3)
    59: 0,   # bed -> bed
    57: 1,   # couch -> sofa  
    56: 2,   # chair -> chair
    60: 3,   # dining table -> table
    
    # æ ¸å¿ƒç”µå™¨ (4-6)  
    74: 4,   # clock -> clock/lamp
    62: 5,   # tv -> tv
    63: 6,   # laptop -> laptop
    
    # æ ¸å¿ƒè£…é¥° (7-11)
    58: 7,   # potted plant -> potted plant
    75: 8,   # vase -> vase/photo frame
    73: 9,   # book -> book
    
    # === æ‰©å……ç±»åˆ« ===
    # é¤å…·å¨å…· (10-19)
    44: 10,  # bottle -> bottle
    46: 11,  # cup -> cup  
    50: 12,  # bowl -> bowl
    45: 13,  # wine glass -> glass
    48: 14,  # knife -> knife
    49: 15,  # spoon -> spoon
    47: 16,  # fork -> fork
    
    # å¨æˆ¿ç”µå™¨ (17-22)
    72: 17,  # refrigerator -> refrigerator
    68: 18,  # microwave -> microwave
    69: 19,  # oven -> oven
    70: 20,  # toaster -> toaster
    71: 21,  # sink -> sink
    
    # å«æµ´è®¾å¤‡ (22-24)
    61: 22,  # toilet -> toilet
    79: 23,  # toothbrush -> toothbrush
    
    # ç”µå­è®¾å¤‡ (24-27)
    66: 24,  # keyboard -> keyboard
    64: 25,  # mouse -> mouse
    67: 26,  # cell phone -> phone
    65: 27,  # remote -> remote
    
    # äººç‰© (é‡è¦çš„å‚è€ƒå¯¹è±¡)
    0: 28,   # person -> person
}

# æ‰©å±•åçš„ç±»åˆ«åç§°
HOMEOBJECTS_EXTENDED_NAMES = {
    # HomeObjectsæ ¸å¿ƒ
    0: 'bed', 1: 'sofa', 2: 'chair', 3: 'table',
    4: 'clock', 5: 'tv', 6: 'laptop',
    7: 'plant', 8: 'vase', 9: 'book',
    
    # é¤å…·å¨å…·
    10: 'bottle', 11: 'cup', 12: 'bowl', 13: 'glass',
    14: 'knife', 15: 'spoon', 16: 'fork',
    
    # å¨æˆ¿ç”µå™¨
    17: 'refrigerator', 18: 'microwave', 19: 'oven', 
    20: 'toaster', 21: 'sink',
    
    # å«æµ´è®¾å¤‡
    22: 'toilet', 23: 'toothbrush',
    
    # ç”µå­è®¾å¤‡
    24: 'keyboard', 25: 'mouse', 26: 'phone', 27: 'remote',
    
    # äººç‰©
    28: 'person'
}

def download_places365_assets(cache_dir: Path):
    """ä¸‹è½½Places365æ¨¡å‹å’Œç›¸å…³æ–‡ä»¶"""
    import urllib.request
    
    cache_dir.mkdir(parents=True, exist_ok=True)  # æ·»åŠ parents=True
    
    assets = {
        'model': ('resnet50_places365.pth.tar', 
                  'https://github.com/CSAILVision/places365/blob/master/resnet50_places365.pth.tar?raw=true'),
        'categories': ('categories_places365.txt',
                      'https://raw.githubusercontent.com/CSAILVision/places365/master/categories_places365.txt'),
        'io_places365': ('IO_places365.txt',
                        'https://raw.githubusercontent.com/CSAILVision/places365/master/IO_places365.txt')
    }
    
    for name, (filename, url) in assets.items():
        filepath = cache_dir / filename
        if not filepath.exists() or filepath.stat().st_size == 0:
            print(f"ä¸‹è½½ {filename}...")
            try:
                urllib.request.urlretrieve(url, filepath)
                print(f"âœ… {filename} ä¸‹è½½å®Œæˆ")
            except Exception as e:
                print(f"âŒ ä¸‹è½½ {filename} å¤±è´¥: {e}")
                raise
        else:
            print(f"âœ… {filename} å·²å­˜åœ¨")

def load_places365_model(weights_path: Path, device):
    """åŠ è½½Places365é¢„è®­ç»ƒæ¨¡å‹"""
    from torchvision.models import resnet50
    
    model = resnet50(weights=None)
    model.fc = nn.Linear(model.fc.in_features, 365)
    
    if weights_path.exists():
        checkpoint = torch.load(weights_path, map_location=device)
        state_dict = {str.replace(k, 'module.', ''): v for k, v in checkpoint['state_dict'].items()}
        model.load_state_dict(state_dict)
    else:
        raise FileNotFoundError(f"æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weights_path}")
    
    model.to(device)
    model.eval()
    return model

def load_places365_io_mapping(io_path: Path):
    """åŠ è½½Places365å®¤å†…/å®¤å¤–æ˜ å°„"""
    io_mapping = []
    with open(io_path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 2:
                # 1=å®¤å†…, 2=å®¤å¤–ï¼Œè½¬æ¢ä¸º1=å®¤å†…, 0=å®¤å¤–
                io_value = int(parts[1])
                io_mapping.append(1 if io_value == 1 else 0)
    return io_mapping

def is_indoor_scene(image_path: Path, model, io_mapping, transform, device, threshold=0.6):
    """åˆ¤æ–­å›¾åƒæ˜¯å¦ä¸ºå®¤å†…åœºæ™¯"""
    try:
        image = Image.open(image_path).convert('RGB')
        input_tensor = transform(image).unsqueeze(0).to(device)
        
        with torch.no_grad():
            output = model(input_tensor)
            probs = torch.nn.functional.softmax(output, dim=1)
            
            # è®¡ç®—åŠ æƒå®¤å†…æ¦‚ç‡
            io_tensor = torch.tensor(io_mapping, device=device, dtype=torch.float32)
            weighted_indoor_prob = (probs[0] * io_tensor).sum()
            
            return weighted_indoor_prob.item() >= threshold
            
    except Exception as e:
        print(f"å¤„ç†å›¾åƒå¤±è´¥ {image_path}: {e}")
        return False

def filter_homeobjects_extended():
    """ä»COCOåŸå§‹æ•°æ®é›†ç­›é€‰HomeObjectsæ‰©å±•ç±»åˆ«ï¼Œä¸¥æ ¼æ’é™¤å®¤å¤–åœºæ™¯"""
    
    source_root = Path('/root/autodl-tmp/database/coco')  # COCOåŸå§‹æ•°æ®é›†è·¯å¾„
    output_root = Path('datasets/homeobjects_extended_yolo_indoor_strict')
    cache_dir = Path('.cache/places365')
    
    if not source_root.exists():
        print("âŒ COCOåŸå§‹æ•°æ®é›†ä¸å­˜åœ¨: /root/autodl-tmp/database/coco")
        print("ğŸ’¡ è¯·ç¡®ä¿COCOæ•°æ®é›†å·²ä¸‹è½½åˆ°è¯¥ç›®å½•")
        return False
        
    if output_root.exists():
        shutil.rmtree(output_root)
    
    # ä¸‹è½½Places365èµ„æº
    print("ğŸ“¥ å‡†å¤‡Places365æ¨¡å‹...")
    download_places365_assets(cache_dir)
    
    # åŠ è½½Places365æ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ¯ ä½¿ç”¨è®¾å¤‡: {device}")
    
    try:
        model = load_places365_model(cache_dir / 'resnet50_places365.pth.tar', device)
        io_mapping = load_places365_io_mapping(cache_dir / 'IO_places365.txt')
        print("âœ… Places365æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ Places365æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False
    
    # å›¾åƒé¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    for split in ['train2017', 'val2017']:
        (output_root / 'images' / split).mkdir(parents=True, exist_ok=True)
        (output_root / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'train': {new_id: 0 for new_id in HOMEOBJECTS_EXTENDED_NAMES.keys()},
        'val': {new_id: 0 for new_id in HOMEOBJECTS_EXTENDED_NAMES.keys()}
    }
    
    file_counts = {'train': 0, 'val': 0}
    indoor_filtered = {'train': 0, 'val': 0}  # å®¤å†…è¿‡æ»¤ç»Ÿè®¡
    skipped_files = {'train': 0, 'val': 0}
    
    # å¤„ç†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    for split_name, split_dir in [('train', 'train2017'), ('val', 'val2017')]:
        labels_dir = source_root / 'labels' / split_dir
        images_dir = source_root / 'images' / split_dir
        
        if not labels_dir.exists():
            print(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨çš„åˆ†å‰²: {split_dir}")
            continue
        
        label_files = list(labels_dir.glob('*.txt'))
        print(f"\nå¤„ç† {split_name}é›†: {len(label_files)} ä¸ªæ–‡ä»¶")
        
        for label_file in tqdm(label_files, desc=f"ä¸¥æ ¼ç­›é€‰{split_name}é›†"):
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡ç±»åˆ«
            with open(label_file, 'r') as f:
                lines = f.readlines()
            
            # è½¬æ¢æ ‡æ³¨ï¼Œåªä¿ç•™ç›®æ ‡ç±»åˆ«
            new_lines = []
            has_target = False
            
            for line in lines:
                parts = line.strip().split()
                if len(parts) >= 5:
                    old_class_id = int(parts[0])
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡ç±»åˆ«
                    if old_class_id in COCO_TO_HOMEOBJECTS_EXTENDED:
                        new_class_id = COCO_TO_HOMEOBJECTS_EXTENDED[old_class_id]
                        parts[0] = str(new_class_id)
                        new_lines.append(' '.join(parts) + '\n')
                        stats[split_name][new_class_id] += 1
                        has_target = True
            
            if not has_target:
                skipped_files[split_name] += 1
                continue
            
            # æ£€æŸ¥å¯¹åº”çš„å›¾åƒæ˜¯å¦ä¸ºå®¤å†…åœºæ™¯
            image_file = images_dir / (label_file.stem + '.jpg')
            if not image_file.exists():
                skipped_files[split_name] += 1
                continue
            
            # ä½¿ç”¨Places365åˆ¤æ–­æ˜¯å¦ä¸ºå®¤å†…åœºæ™¯
            if not is_indoor_scene(image_file, model, io_mapping, transform, device, threshold=0.7):
                indoor_filtered[split_name] += 1
                continue
            
            # ä¿å­˜é€šè¿‡ç­›é€‰çš„æ–‡ä»¶
            shutil.copy2(image_file, output_root / 'images' / split_dir)
            
            # ä¿å­˜ç­›é€‰åçš„æ ‡æ³¨
            output_label = output_root / 'labels' / split_dir / label_file.name
            with open(output_label, 'w') as f:
                f.writelines(new_lines)
            
            file_counts[split_name] += 1
    
    # åˆ›å»ºYOLOé…ç½®æ–‡ä»¶
    config = {
        'path': str(output_root.resolve()),
        'train': 'images/train2017',
        'val': 'images/val2017',
        'names': HOMEOBJECTS_EXTENDED_NAMES,
        'nc': len(HOMEOBJECTS_EXTENDED_NAMES)
    }
    
    with open(output_root / 'homeobjects_extended_indoor_strict.yaml', 'w') as f:
        yaml.safe_dump(config, f, default_flow_style=False)
    
    # è¾“å‡ºè¯¦ç»†ç»Ÿè®¡
    print("\n" + "="*80)
    print("ğŸ  HomeObjectsä¸¥æ ¼å®¤å†…æ•°æ®é›†ç»Ÿè®¡ (æ’é™¤å®¤å¤–åœºæ™¯)")
    print("="*80)
    
    total_files = sum(file_counts.values())
    total_objects = sum(sum(stats[split].values()) for split in ['train', 'val'])
    total_skipped = sum(skipped_files.values())
    total_outdoor_filtered = sum(indoor_filtered.values())
    
    print(f"ğŸ“Š ç­›é€‰ç»Ÿè®¡:")
    print(f"   ä¿ç•™å›¾åƒ: {total_files}")
    print(f"   æ— ç›®æ ‡ç±»åˆ«: {total_skipped}")
    print(f"   å®¤å¤–åœºæ™¯è¿‡æ»¤: {total_outdoor_filtered}")
    print(f"   æ€»å¤„ç†æ•°: {total_files + total_skipped + total_outdoor_filtered}")
    print(f"   æœ€ç»ˆç­›é€‰ç‡: {total_files/(total_files + total_skipped + total_outdoor_filtered)*100:.1f}%")
    print(f"   å®¤å†…çº¯åº¦: {total_files/(total_files + total_outdoor_filtered)*100:.1f}%")
    
    print(f"\nğŸ“Š è´¨é‡ç»Ÿè®¡:")
    print(f"   æ€»ç›®æ ‡æ•°: {total_objects}")
    print(f"   å¹³å‡æ¯å›¾: {total_objects/max(total_files,1):.1f} ä¸ªç›®æ ‡")
    print(f"   ç±»åˆ«æ•°é‡: {len(HOMEOBJECTS_EXTENDED_NAMES)}")
    
    print(f"\nğŸ“ æ•°æ®åˆ†å¸ƒ:")
    print(f"   è®­ç»ƒé›†: {file_counts['train']} å¼ å›¾åƒ ({file_counts['train']/max(total_files,1)*100:.1f}%)")
    print(f"   éªŒè¯é›†: {file_counts['val']} å¼ å›¾åƒ ({file_counts['val']/max(total_files,1)*100:.1f}%)")
    
    # ç®€åŒ–ç±»åˆ«ç»Ÿè®¡ï¼Œåªæ˜¾ç¤ºæ ·æœ¬æ•°å‰15çš„ç±»åˆ«
    print(f"\nğŸ“‹ ä¸»è¦ç±»åˆ«ç»Ÿè®¡ (TOP 15):")
    print("ID  ç±»åˆ«åç§°         è®­ç»ƒé›†   éªŒè¯é›†    æ€»è®¡     å æ¯”")
    print("-" * 55)
    
    # è®¡ç®—å„ç±»åˆ«æ€»æ•°å¹¶æ’åº
    category_totals = []
    for class_id in HOMEOBJECTS_EXTENDED_NAMES.keys():
        train_count = stats['train'][class_id]
        val_count = stats['val'][class_id]
        total_count = train_count + val_count
        if total_count > 0:
            category_totals.append((total_count, class_id, train_count, val_count))
    
    category_totals.sort(reverse=True)
    
    for i, (total_count, class_id, train_count, val_count) in enumerate(category_totals[:15]):
        percentage = total_count / max(total_objects, 1) * 100
        class_name = HOMEOBJECTS_EXTENDED_NAMES[class_id]
        print(f"{class_id:2d}  {class_name:15s}  {train_count:6d}   {val_count:6d}   {total_count:6d}   {percentage:5.1f}%")
    
    # æ•°æ®è´¨é‡è¯„ä¼°
    non_zero_counts = [total for total, _, _, _ in category_totals]
    
    if non_zero_counts:
        min_samples = min(non_zero_counts)
        max_samples = max(non_zero_counts)
        active_classes = len(non_zero_counts)
        
        print(f"\nğŸ“ˆ æ•°æ®è´¨é‡:")
        print(f"   æœ‰æ•ˆç±»åˆ«: {active_classes}/{len(HOMEOBJECTS_EXTENDED_NAMES)}")
        print(f"   æœ€å°‘æ ·æœ¬: {min_samples}")
        print(f"   æœ€å¤šæ ·æœ¬: {max_samples}")
        print(f"   æ ·æœ¬å‡è¡¡åº¦: {min_samples/max(max_samples,1)*100:.1f}%")
    
    return True

if __name__ == "__main__":
    print("ğŸ¯ å¼€å§‹ä»COCOç­›é€‰HomeObjectsæ‰©å±•æ•°æ®é›†ï¼ˆä¸¥æ ¼å®¤å†…ç­›é€‰ï¼‰...")
    print("ğŸ“‹ ç›®æ ‡ï¼šHomeObjectsæ ¸å¿ƒç±»åˆ« + å®¶å…·ç”µå™¨å®¶å±…ç”¨å“æ‰©å……")
    print("ğŸ  ç±»åˆ«è¦†ç›–ï¼š")
    print("   â€¢ æ ¸å¿ƒå®¶å…·: bed, sofa, chair, table")
    print("   â€¢ ç”µå™¨è®¾å¤‡: tv, laptop, clock, refrigerator, microwave, ovenç­‰")
    print("   â€¢ å®¶å±…ç”¨å“: plant, vase, book, bottle, cup, bowlç­‰")
    print("   â€¢ é¤å…·å¨å…·: knife, spoon, fork, glassç­‰")
    print("   â€¢ å«æµ´ç”¨å“: toilet, toothbrushç­‰")
    print("   â€¢ ç”µå­è®¾å¤‡: keyboard, mouse, phone, remoteç­‰")
    print(f"   æ€»è®¡ {len(HOMEOBJECTS_EXTENDED_NAMES)} ä¸ªç±»åˆ«")
    print("\nğŸ” ä¸¥æ ¼ç­›é€‰è§„åˆ™:")
    print("   â€¢ åªä¿ç•™åŒ…å«ç›®æ ‡ç±»åˆ«çš„å›¾åƒ")
    print("   â€¢ ä½¿ç”¨Places365æ¨¡å‹æ’é™¤å®¤å¤–åœºæ™¯")
    print("   â€¢ å®¤å†…åˆ¤æ–­é˜ˆå€¼: 70%")
    print("   â€¢ ç¡®ä¿æ•°æ®é›†çš„å®¤å†…åœºæ™¯çº¯åº¦")
    
    success = filter_homeobjects_extended()
    
    if success:
        print("\nâœ… HomeObjectsä¸¥æ ¼å®¤å†…æ•°æ®é›†ç­›é€‰å®Œæˆï¼")
        print("ğŸ“ æ•°æ®é›†ä½ç½®: ./datasets/homeobjects_extended_yolo_indoor_strict/")
        print("ğŸ“„ é…ç½®æ–‡ä»¶: ./datasets/homeobjects_extended_yolo_indoor_strict/homeobjects_extended_indoor_strict.yaml")
        print("\nğŸš€ é«˜è´¨é‡å®¤å†…æ•°æ®é›†å·²å‡†å¤‡å¥½ç”¨äºRT-DETRè®­ç»ƒï¼")
        print("ğŸ’¡ æ­¤æ•°æ®é›†ç»è¿‡ä¸¥æ ¼ç­›é€‰ï¼Œç¡®ä¿å…¨éƒ¨ä¸ºå®¤å†…åœºæ™¯")
    else:
        print("\nâŒ æ•°æ®é›†ç­›é€‰å¤±è´¥")