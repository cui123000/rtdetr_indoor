#!/usr/bin/env python3
"""
RT-DETR with MobileNetV4 Training Script
ç»Ÿä¸€çš„è®­ç»ƒé…ç½®ï¼Œæ”¯æŒä¸‰ä¸ªä¸»è¦ç‰ˆæœ¬ï¼šåŸå§‹ã€MobileNetV4æ··åˆã€MobileNetV4+SEAä¼˜åŒ–
"""

import os
import sys
import yaml
import torch
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent  # ä»scripts/training/å›åˆ°é¡¹ç›®æ ¹ç›®å½•
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "ultralytics"))

# å®šä¹‰å¯ç”¨çš„æ¨¡å‹ç‰ˆæœ¬ - ç®€åŒ–ä¸ºä¸‰ä¸ªä¸»è¦ç‰ˆæœ¬
MODEL_VERSIONS = {
    '1': {
        'name': 'Original RT-DETR (åŸå§‹ç‰ˆæœ¬)',
        'file': 'rtdetr-l.yaml',
        'description': 'åŸå§‹RT-DETR-Læ¨¡å‹ï¼Œæ ‡å‡†åŸºå‡†',
        'modules': ['HGStem', 'HGBlock', 'RepC3', 'AIFI'],
        'status': 'ğŸ“Š åŸºå‡†æ¨¡å‹'
    },
    '2': {
        'name': 'RT-DETR + MobileNetV4 Hybrid (æ··åˆç‰ˆæœ¬)',
        'file': 'rtdetr-mnv4-hybrid-m.yaml',
        'description': 'é›†æˆMobileNetV4æ··åˆæ¶æ„çš„é«˜æ•ˆç‰ˆæœ¬',
        'modules': ['EdgeResidual', 'UniversalInvertedResidual', 'C2f', 'RepC3', 'AIFI'],
        'status': 'ğŸš€ ç§»åŠ¨ä¼˜åŒ–'
    },
    '3': {
        'name': 'RT-DETR + MobileNetV4 + SEA Attention (SEAä¼˜åŒ–ç‰ˆæœ¬)',
        'file': 'rtdetr-mnv4-hybrid-m-sea.yaml', 
        'description': 'MobileNetV4 + ä¼˜åŒ–SEAæ³¨æ„åŠ›æœºåˆ¶çš„æœ€å¼ºç‰ˆæœ¬',
        'modules': ['EdgeResidual', 'UniversalInvertedResidual', 'Sea_Attention_Simplified', 'OptimizedSEA_Attention', 'TransformerEnhancedSEA', 'C2f', 'RepC3'],
        'status': 'ğŸŒŸ SEAå¢å¼º'
    }
}

def select_model_version():
    """é€‰æ‹©æ¨¡å‹ç‰ˆæœ¬"""
    print("\nğŸ“‹ å¯ç”¨çš„RT-DETRæ¨¡å‹ç‰ˆæœ¬:")
    print("=" * 80)
    
    for key, version in MODEL_VERSIONS.items():
        print(f"{key}. {version['name']}")
        print(f"   ğŸ“„ é…ç½®æ–‡ä»¶: {version['file']}")
        print(f"   ğŸ“ æè¿°: {version['description']}")
        print(f"   ğŸ§© æ ¸å¿ƒæ¨¡å—: {', '.join(version['modules'][:3])}{'...' if len(version['modules']) > 3 else ''}")
        print(f"   ğŸ“Š çŠ¶æ€: {version['status']}")
        print()
    
    while True:
        try:
            choice = input("è¯·é€‰æ‹©ç‰ˆæœ¬ (1-3): ").strip()
            if choice in MODEL_VERSIONS:
                selected = MODEL_VERSIONS[choice]
                print(f"\nâœ… å·²é€‰æ‹©: {selected['name']}")
                print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {selected['file']}")
                return selected['file'], choice
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-3")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ é€€å‡ºç¨‹åº")
            sys.exit(0)
        except Exception as e:
            print(f"âŒ è¾“å…¥é”™è¯¯: {e}")

def create_training_config(model_file, version_choice):
    """åˆ›å»ºç»Ÿä¸€çš„è®­ç»ƒé…ç½®"""
    model_path = f'/home/cui/rtdetr_indoor/ultralytics/ultralytics/cfg/models/rt-detr/{model_file}'
    
    # ç»Ÿä¸€çš„åŸºç¡€è®­ç»ƒé…ç½®
    config = {
        # åŸºæœ¬è®¾ç½®
        'task': 'detect',
        'mode': 'train',
        
        # æ¨¡å‹å’Œæ•°æ®
        'model': model_path,
        'data': '/home/cui/rtdetr_indoor/datasets/homeobjects-3K/HomeObjects-3K.yaml',
        
        # ç»Ÿä¸€è®­ç»ƒå‚æ•° - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
        'epochs': 100,
        'batch': 4,              # å¤§å¹…å‡å°‘batch sizeä»¥èŠ‚çœæ˜¾å­˜
        'imgsz': 640,
        'patience': 20,          # æ—©åœè€å¿ƒ
        
        # ä¿å­˜è®¾ç½®
        'save': True,
        'save_period': 5,        # æ¯5è½®ä¿å­˜ä¸€æ¬¡
        'project': 'runs/detect',
        'name': f'rtdetr_{model_file.replace(".yaml", "").replace("-", "_")}',
        'exist_ok': True,
        
        # è®¾å¤‡è®¾ç½® - å†…å­˜ä¼˜åŒ–
        'device': '0',
        'workers': 4,            # å‡å°‘workersä»¥èŠ‚çœCPUå†…å­˜
        'amp': True,             # æ··åˆç²¾åº¦è®­ç»ƒ
        
        # éªŒè¯è®¾ç½®
        'val': True,
        'conf': 0.25,
        'iou': 0.7,
        'max_det': 300,
        
        # ä¼˜åŒ–å™¨è®¾ç½® - æ ¹æ®ç‰ˆæœ¬ä¼˜åŒ–
        'optimizer': 'AdamW',
        'lr0': 0.001,            # åˆå§‹å­¦ä¹ ç‡
        'lrf': 0.01,             # æœ€ç»ˆå­¦ä¹ ç‡æ¯”ä¾‹
        'momentum': 0.937,
        'weight_decay': 0.0005,
        'warmup_epochs': 3.0,
        'cos_lr': True,          # ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦
        
        # æ•°æ®å¢å¼ºç­–ç•¥ - å‡å°‘å†…å­˜æ¶ˆè€—çš„å¢å¼º
        'hsv_h': 0.015,          # è‰²è°ƒå˜åŒ–
        'hsv_s': 0.7,            # é¥±å’Œåº¦å˜åŒ–
        'hsv_v': 0.4,            # äº®åº¦å˜åŒ–
        'degrees': 5.0,          # æ—‹è½¬è§’åº¦
        'translate': 0.1,        # å¹³ç§»
        'scale': 0.5,            # ç¼©æ”¾
        'shear': 2.0,            # å‰ªåˆ‡
        'perspective': 0.0,      # é€è§†å˜æ¢
        'flipud': 0.0,           # å‚ç›´ç¿»è½¬
        'fliplr': 0.5,           # æ°´å¹³ç¿»è½¬
        'mosaic': 0.5,           # å‡å°‘Mosaicå¢å¼ºä»¥èŠ‚çœå†…å­˜
        'mixup': 0.0,            # å…³é—­Mixupä»¥èŠ‚çœå†…å­˜
        'copy_paste': 0.0,       # å…³é—­Copy-pasteä»¥èŠ‚çœå†…å­˜
        
        # æŸå¤±æƒé‡
        'box': 7.5,              # è¾¹ç•Œæ¡†æŸå¤±æƒé‡
        'cls': 0.5,              # åˆ†ç±»æŸå¤±æƒé‡
        'dfl': 1.5,              # åˆ†å¸ƒç„¦ç‚¹æŸå¤±æƒé‡
        
        # å…¶ä»–è®¾ç½® - å†…å­˜ä¼˜åŒ–
        'verbose': True,
        'seed': 42,
        'deterministic': False,
        'plots': True,
        'cache': False,          # å…³é—­ç¼“å­˜ä»¥èŠ‚çœå†…å­˜
        'close_mosaic': 10,      # æœ€å10è½®å…³é—­mosaic
    }
    
    # æ ¹æ®ä¸åŒç‰ˆæœ¬è¿›è¡Œå¾®è°ƒ
    if version_choice == '1':  # åŸå§‹RT-DETR
        print("ğŸ¯ ä½¿ç”¨åŸå§‹RT-DETRé…ç½®...")
        config.update({
            'lr0': 0.001,          # æ ‡å‡†å­¦ä¹ ç‡
            'batch': 4,            # åŸå§‹æ¨¡å‹batch size
            'warmup_epochs': 5.0,  # æ›´é•¿é¢„çƒ­
        })
        
    elif version_choice == '2':  # MobileNetV4æ··åˆç‰ˆæœ¬
        print("ğŸš€ ä½¿ç”¨MobileNetV4æ··åˆç‰ˆæœ¬é…ç½®...")
        config.update({
            'lr0': 0.0008,         # ç¨å¾®é™ä½å­¦ä¹ ç‡
            'batch': 4,            # é€‚ä¸­batch size
            'weight_decay': 0.0008, # ç¨å¾®å¢åŠ æƒé‡è¡°å‡
        })
        
    elif version_choice == '3':  # SEAä¼˜åŒ–ç‰ˆæœ¬
        print("ğŸŒŸ ä½¿ç”¨SEAæ³¨æ„åŠ›ä¼˜åŒ–é…ç½®...")
        config.update({
            'lr0': 0.0005,         # æ›´ä¿å®ˆçš„å­¦ä¹ ç‡
            'batch': 4,            # æœ€å°batch sizeä»¥é€‚åº”å¤æ‚æ¨¡å‹
            'warmup_epochs': 5.0,  # æ›´é•¿é¢„çƒ­æœŸ
            'weight_decay': 0.001, # æ›´å¼ºçš„æ­£åˆ™åŒ–
            'patience': 25,        # æ›´å¤šè€å¿ƒ
            'cos_lr': True,        # ç¡®ä¿ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡
            'workers': 4,          # è¿›ä¸€æ­¥å‡å°‘workers
        })
    
    return config

def setup_environment():
    """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
    print("ğŸ”§ è®¾ç½®è®­ç»ƒç¯å¢ƒ...")
    
    # è®¾ç½®CUDAå†…å­˜ç®¡ç†
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # å¯ç”¨CUDAé˜»å¡æ¨¡å¼ä»¥ä¾¿è°ƒè¯•
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'  # é™åˆ¶CUDAå†…å­˜åˆ†é…
    
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if torch.cuda.is_available():
        print(f"ğŸ”¥ CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ® CUDA version: {torch.version.cuda}")
        
        # è·å–GPUå†…å­˜ä¿¡æ¯
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"   GPUæ€»å†…å­˜: {gpu_memory:.1f}GB")
        
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        
        # è·å–å½“å‰å¯ç”¨å†…å­˜
        available_memory = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)
        print(f"   GPUå¯ç”¨å†…å­˜: {available_memory / 1e9:.1f}GB")
        
        # è®¾ç½®å†…å­˜åˆ†æ•°ä»¥é˜²æ­¢OOM
        torch.cuda.set_per_process_memory_fraction(0.9)  # ä½¿ç”¨90%çš„GPUå†…å­˜
        print("   âš™ï¸ è®¾ç½®GPUå†…å­˜ä½¿ç”¨é™åˆ¶: 90%")
        
    else:
        print("ğŸ’» CUDA is not available. Using CPU.")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['PYTHONPATH'] = f"{project_root}:{project_root}/ultralytics"
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    os.environ['TORCH_HOME'] = '/home/cui/.cache/torch'
    
    # è®¾ç½®PyTorchæ•°å€¼ç¨³å®šæ€§
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = False
    
    # éªŒè¯æ ¸å¿ƒæ¨¡å—å¯¼å…¥
    try:
        # æ·»åŠ ultralyticsè·¯å¾„
        ultralytics_path = "/home/cui/rtdetr_indoor/ultralytics"
        if ultralytics_path not in sys.path:
            sys.path.insert(0, ultralytics_path)
        
        from ultralytics import RTDETR
        print("âœ… RTDETRæ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # éªŒè¯SEAæ³¨æ„åŠ›æ¨¡å—
        from ultralytics.nn.modules.sea_attention import (
            Sea_Attention_Simplified, OptimizedSEA_Attention, TransformerEnhancedSEA
        )
        print("âœ… SEAæ³¨æ„åŠ›æ¨¡å—å¯¼å…¥æˆåŠŸ")
        print("  ï¿½ Sea_Attention_Simplified - ç®€åŒ–ç‰ˆSEAæ³¨æ„åŠ›")
        print("  âš¡ OptimizedSEA_Attention - ä¼˜åŒ–ç‰ˆSEAæ³¨æ„åŠ›") 
        print("  ğŸŒŸ TransformerEnhancedSEA - Transformerå¢å¼ºSEA")
        
        from ultralytics.nn.modules import Conv
        print("âœ… åŸºç¡€æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
        print("ï¿½ è¯·æ£€æŸ¥ä»¥ä¸‹é…ç½®:")
        print("   1. ultralyticsè·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("   2. SEAæ³¨æ„åŠ›æ¨¡å—æ˜¯å¦æ­£ç¡®æ³¨å†Œ")
        print("   3. ç›¸å…³ä¾èµ–æ˜¯å¦å®‰è£…")
        return False
        print("ğŸ“ å¢å¼ºæ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å—")

def check_gpu_memory():
    """æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        device = torch.cuda.current_device()
        total_memory = torch.cuda.get_device_properties(device).total_memory / 1e9
        allocated_memory = torch.cuda.memory_allocated(device) / 1e9
        cached_memory = torch.cuda.memory_reserved(device) / 1e9
        free_memory = total_memory - cached_memory
        
        print(f"\nğŸ“Š GPUå†…å­˜ä½¿ç”¨æƒ…å†µ:")
        print(f"   æ€»å†…å­˜: {total_memory:.1f}GB")
        print(f"   å·²åˆ†é…: {allocated_memory:.1f}GB")
        print(f"   å·²ç¼“å­˜: {cached_memory:.1f}GB") 
        print(f"   å¯ç”¨å†…å­˜: {free_memory:.1f}GB")
        
        if free_memory < 2.0:
            print("âš ï¸ å¯ç”¨GPUå†…å­˜ä¸è¶³2GBï¼Œå»ºè®®:")
            print("   1. è¿›ä¸€æ­¥å‡å°‘batch size")
            print("   2. é™ä½å›¾åƒåˆ†è¾¨ç‡")
            print("   3. å…³é—­æ›´å¤šæ•°æ®å¢å¼º")
            return False
        return True
    return True

def test_model_loading(model_path):
    """æµ‹è¯•æ¨¡å‹æ˜¯å¦èƒ½æ­£å¸¸åŠ è½½"""
    try:
        print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹åŠ è½½: {os.path.basename(model_path)}")
        
        from ultralytics import RTDETR
        model = RTDETR(model_path)
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in model.model.parameters())
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"ğŸ“Š æ€»å‚æ•°é‡: {total_params:,}")
        
        # ç®€å•çš„å‰å‘ä¼ æ’­æµ‹è¯•
        import torch
        if torch.cuda.is_available():
            device = 'cuda'
            x = torch.randn(1, 3, 640, 640).cuda()
            model.model.cuda()
        else:
            device = 'cpu'
            x = torch.randn(1, 3, 640, 640)
            
        model.model.eval()
        with torch.no_grad():
            output = model.model(x)
        print(f"âœ… å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡! (è®¾å¤‡: {device})")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ å»ºè®®æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–é€‰æ‹©å…¶ä»–ç‰ˆæœ¬")
        return False

def check_model_config(model_file):
    """æ£€æŸ¥æ¨¡å‹é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    model_config_path = Path(f"/home/cui/rtdetr_indoor/ultralytics/ultralytics/cfg/models/rt-detr/{model_file}")
    if not model_config_path.exists():
        print(f"âŒ Model config file not found: {model_config_path}")
        return False
    
    print(f"âœ… Model config file found: {model_config_path}")
    return True

def check_dataset_config():
    """æ£€æŸ¥æ•°æ®é›†é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     
    # æ£€æŸ¥homeobjects-3Kæ•°æ®é›†
    dataset_config_path = Path("/home/cui/rtdetr_indoor/datasets/homeobjects-3K/HomeObjects-3K.yaml")
    if dataset_config_path.exists():
        print(f"âœ… HomeObjects-3K dataset config found: {dataset_config_path}")
        return True
    
    print(f"âŒ Dataset config file not found in both locations")
    print("Please make sure your dataset is properly configured.")
    return False

def train_model(config):
    """è®­ç»ƒæ¨¡å‹"""
    try:
        # å¯¼å…¥Ultralytics YOLO
        from ultralytics import RTDETR
        
        print("\nğŸš€ Starting RT-DETR with MobileNetV4 training...")
        print(f"ğŸ“Š Configuration:")
        for key, value in config.items():
            if key != 'model':  # ä¸æ‰“å°å®Œæ•´è·¯å¾„
                print(f"  {key}: {value}")
        print(f"  model: {Path(config['model']).name}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        print("\nğŸ“¦ Loading RT-DETR with MobileNetV4 model...")
        model = RTDETR(config['model'])
        
        # å¼€å§‹è®­ç»ƒ
        print("\nğŸƒ Starting training...")
        results = model.train(**config)
        
        print("\nğŸ‰ Training completed successfully!")
        print(f"ğŸ“ Results saved to: {config['project']}/{config['name']}")
        
        return results
        
    except Exception as e:
        print(f"âŒ Training failed with error: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¤– RT-DETR with MobileNetV4 Training Script")
    print("ğŸ¯ æ”¯æŒå¤šç‰ˆæœ¬é€‰æ‹©å’Œæ¨¡å‹æµ‹è¯•")
    print("=" * 60)
    
    # è®¾ç½®ç¯å¢ƒ
    setup_environment()
    
    # é€‰æ‹©æ¨¡å‹ç‰ˆæœ¬
    selected_file, version_choice = select_model_version()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not check_model_config(selected_file):
        sys.exit(1)
    
    # åˆ›å»ºè®­ç»ƒé…ç½®
    model_path = f'/home/cui/rtdetr_indoor/ultralytics/ultralytics/cfg/models/rt-detr/{selected_file}'
    
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    if not test_model_loading(model_path):
        print("\nâŒ æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥!")
        print("ğŸ’¡ å»ºè®®:")
        print("  1. æ£€æŸ¥é…ç½®æ–‡ä»¶è¯­æ³•")
        print("  2. ç¡®ä¿æ‰€æœ‰è‡ªå®šä¹‰æ¨¡å—å·²æ­£ç¡®å®ç°")
        print("  3. é€‰æ‹©å…¶ä»–ç¨³å®šç‰ˆæœ¬")
        print("  4. æˆ–è€…è·³è¿‡æµ‹è¯•ç›´æ¥å¼€å§‹è®­ç»ƒ")
        
        print("\nâ“ æ˜¯å¦è·³è¿‡æµ‹è¯•ç›´æ¥å¼€å§‹è®­ç»ƒ? (y/N)")
        choice = input().strip().lower()
        if choice != 'y':
            print("ğŸ‘‹ é€€å‡ºç¨‹åº")
            sys.exit(1)
        else:
            print("âš ï¸ è·³è¿‡æ¨¡å‹æµ‹è¯•ï¼Œç›´æ¥å¼€å§‹è®­ç»ƒ...")
    
    # æ£€æŸ¥æ•°æ®é›†
    if not check_dataset_config():
        print("âš ï¸  Dataset config not found, but continuing with training...")
    
    # åˆ›å»ºè®­ç»ƒé…ç½®
    config = create_training_config(selected_file, version_choice)
    
    # æ£€æŸ¥GPUå†…å­˜
    print("\nğŸ” æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ...")
    if not check_gpu_memory():
        print("\nâ“ GPUå†…å­˜å¯èƒ½ä¸è¶³ï¼Œæ˜¯å¦ç»§ç»­è®­ç»ƒ? (y/N)")
        choice = input().strip().lower()
        if choice != 'y':
            print("ğŸ‘‹ é€€å‡ºç¨‹åº")
            sys.exit(1)
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("\nğŸ“‹ è®­ç»ƒé…ç½®æ‘˜è¦:")
    print(f"  ğŸ¯ æ¨¡å‹: {os.path.basename(config['model'])}")
    print(f"  ğŸ“Š æ•°æ®é›†: {config['data']}")
    print(f"  ğŸ”„ è®­ç»ƒè½®æ¬¡: {config['epochs']}")
    print(f"  ğŸ“¦ æ‰¹æ¬¡å¤§å°: {config['batch']} (å†…å­˜ä¼˜åŒ–)")
    print(f"  ğŸ“ å›¾åƒå°ºå¯¸: {config['imgsz']}")
    print(f"  ğŸ“ å­¦ä¹ ç‡: {config['lr0']}")
    print(f"  ğŸ‘¥ Workers: {config.get('workers', 4)}")
    print(f"  ğŸ’¾ ä¿å­˜è·¯å¾„: {config['project']}/{config['name']}")
    
    # æ ¹æ®ç‰ˆæœ¬æ˜¾ç¤ºç‰¹ç‚¹
    if version_choice == '1':
        print("\nğŸ“Š åŸå§‹RT-DETRé…ç½®:")
        print("  âœ… æ ‡å‡†Transformeræ¶æ„")
        print("  ğŸ“ˆ åŸºå‡†æ€§èƒ½å‚è€ƒ")
    elif version_choice == '2':
        print("\nğŸš€ MobileNetV4æ··åˆç‰ˆæœ¬:")
        print("  âš¡ ç§»åŠ¨ç«¯ä¼˜åŒ–æ¶æ„")
        print("  ğŸ”§ EdgeResidual + UniversalInvertedResidual")
        print("  ğŸ“ˆ å¹³è¡¡æ€§èƒ½ä¸æ•ˆç‡")
    elif version_choice == '3':
        print("\nğŸŒŸ SEAæ³¨æ„åŠ›ä¼˜åŒ–ç‰ˆæœ¬:")
        print("  ğŸ§  Squeeze-enhanced Axial Attention")
        print("  ğŸ¯ æ£€æµ‹æ„ŸçŸ¥çš„ç‰¹å¾æå–")
        print("  ğŸ“ˆ æœ€é«˜æ€§èƒ½é¢„æœŸ")
        print("  âš ï¸ ä½¿ç”¨æœ€å°batch sizeä»¥é€‚åº”å¤æ‚æ¨¡å‹")
    
    # è®­ç»ƒæ¨¡å‹
    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ {selected_file} ç‰ˆæœ¬...")
    if version_choice in ['8', '9']:
        if version_choice == '8':
            print("ï¿½ ä½¿ç”¨åŸå§‹SEAæ³¨æ„åŠ›ç»¼åˆä¼˜åŒ–ç­–ç•¥è®­ç»ƒ!")
            print("ğŸ”¥ SeaFormeråŸå§‹å®ç°: è½´å‘æ³¨æ„åŠ›+ç»†èŠ‚å¢å¼º+é—¨æ§æœºåˆ¶")
        else:
            print("ğŸ¯ ä½¿ç”¨æ ‡å‡†æ¨¡å—ç»¼åˆä¼˜åŒ–ç­–ç•¥è®­ç»ƒ!")
        print("ğŸ“ˆ ç›®æ ‡: mAP50ä»åŸºå‡†çº¿æå‡12-15%")
        print("ğŸš€ é›†æˆç­–ç•¥1+2+4: ç‰¹å¾èåˆ+æ³¨æ„åŠ›+æ¶æ„å¾®è°ƒ")
        print("âš ï¸  è®­ç»ƒæ—¶é—´: 10-12å°æ—¶ (æœ€é«˜è´¨é‡è®­ç»ƒ)")
    elif version_choice == '7':
        print("ğŸ“Š ä½¿ç”¨åŸå§‹RT-DETRè®­ç»ƒ!")
        print("ğŸ“ˆ åŸºå‡†æ€§èƒ½å‚è€ƒ")
    else:
        print("ğŸ”§ ä½¿ç”¨æ ‡å‡†é…ç½®è®­ç»ƒ!")
        print("ğŸ“ˆ æ ‡å‡†æ€§èƒ½é¢„æœŸ")
    
    # å¼€å§‹è®­ç»ƒ
    print("=" * 60)
    
    try:
        from ultralytics import RTDETR
        
        # åˆ›å»ºæ¨¡å‹
        model = RTDETR(config['model'])
        
        # å¼€å§‹è®­ç»ƒ
        results = model.train(**config)
        
        print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“Š æœ€ä½³ç»“æœä¿å­˜åœ¨: {results.save_dir}")
        print("âœ… RT-DETR MobileNetV4 è®­ç»ƒè„šæœ¬æˆåŠŸå®Œæˆ!")
        
        return results
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®é›†è®¾ç½®")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
