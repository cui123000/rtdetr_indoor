#!/usr/bin/env python3
"""
è®­ç»ƒå•ä¸ª RT-DETR å˜ä½“ (Lã€MNV4ã€MNV4+SEAã€MNV4+SEA+BiFPN-Lite)ã€‚
åœ¨è„šæœ¬ä¸­ä¿®æ”¹ SELECTED_VARIANT_KEY ä»¥é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹ã€‚
é»˜è®¤é…ç½®é’ˆå¯¹ RTX 4090 (24 GB) è°ƒæ•´ï¼Œå…¼é¡¾æ˜¾å­˜ä¸ååã€‚
"""

from __future__ import annotations

import argparse
import gc
import json
import sys
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional

import torch

# ============ åœ¨æ­¤å¤„ä¿®æ”¹è¦è®­ç»ƒçš„æ¨¡å‹ ============
SELECTED_VARIANT_KEY = "rtdetr_mnv4_sea_asff_v3"  # å¯é€‰: rtdetr_l, rtdetr_mnv4, rtdetr_mnv4_sea, rtdetr_mnv4_sea_bifpn, rtdetr_mnv4_sea_asff, rtdetr_mnv4_sea_asff_v2
# ============================================

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "ultralytics"))

try:
    from ultralytics import RTDETR  # type: ignore
except ImportError as exc:  # pragma: no cover - import guard
    raise SystemExit(f"Ultralytics å¯¼å…¥å¤±è´¥: {exc}") from exc

DATA_CONFIG = "/home/cui/rtdetr_indoor/datasets/homeobjects-3K/HomeObjects-3K.yaml"
MODEL_DIR = project_root / "ultralytics" / "ultralytics" / "cfg" / "models" / "rt-detr"
DEFAULT_PROJECT = "runs/detect"


@dataclass
class VariantConfig:
    key: str
    label: str
    yaml_file: str
    batch: int
    lr0: float
    workers: int
    description: str


VARIANTS = [
    VariantConfig(
        key="rtdetr_l",
        label="RT-DETR-L",
        yaml_file="rtdetr-l.yaml",
        batch=12,
        lr0=0.0022,
        workers=4,
        description="åŸºç¡€å¤§æ¨¡å‹ï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒ",
    ),
    VariantConfig(
        key="rtdetr_mnv4",
        label="RT-DETR-MNV4",
        yaml_file="rtdetr-mnv4-hybrid-m.yaml",
        batch=8,
        lr0=0.0018,
        workers=4,
        description="MobileNetV4æ··åˆä¸»å¹²ï¼Œè½»é‡åŸºçº¿",
    ),
    VariantConfig(
        key="rtdetr_mnv4_sea",
        label="RT-DETR-MNV4-SEA",
        yaml_file="rtdetr-mnv4-hybrid-m-sea.yaml",
        batch=6,
        lr0=0.0015,
        workers=4,
        description="åŠ å…¥SEAæ³¨æ„åŠ›çš„æ”¹è¿›ç‰ˆ",
    ),
    VariantConfig(
        key="rtdetr_mnv4_sea_bifpn",
        label="RT-DETR-MNV4-SEA-BiFPN",
        yaml_file="rtdetr-mnv4-hybrid-m-sea-bifpn-lite.yaml",
        batch=6,
        lr0=0.0016,
        workers=4,
        description="SEA + BiFPN-Lite èåˆç‰ˆæœ¬",
    ),
    VariantConfig(
        key="rtdetr_mnv4_sea_asff",
        label="RT-DETR-MNV4-SEA-ASFF",
        yaml_file="rtdetr-mnv4-hybrid-m-sea-asff-dysample.yaml",
        batch=8,
        lr0=0.0017,
        workers=4,
        description="SEA + ASFF + DySample è½»é‡é«˜æ•ˆèåˆç‰ˆæœ¬ï¼ˆv1-å¤±è´¥ï¼‰",
    ),
    VariantConfig(
        key="rtdetr_mnv4_sea_asff_v2",
        label="RT-DETR-MNV4-SEA-ASFF-v2",
        yaml_file="rtdetr-mnv4-hybrid-m-sea-asff-v2.yaml",
        batch=8,
        lr0=0.0016,
        workers=4,
        description="SEA + å®Œæ•´ä¸‰å°ºåº¦ASFFï¼Œ256é€šé“ï¼ŒRepC3Ã—3ï¼ˆv2-å®Œæ•´ç‰ˆï¼‰",
    ),
    VariantConfig(
        key="rtdetr_mnv4_sea_asff_v3",
        label="RT-DETR-MNV4-SEA-ASFF-v3",
        yaml_file="rtdetr-mnv4-hybrid-m-sea-asff-v3.yaml",
        batch=8,
        lr0=0.0016,
        workers=4,
        description="SEA + å®Œæ•´ä¸‰å°ºåº¦ASFFï¼Œ224é€šé“ï¼ŒRepC3Ã—2ï¼ˆv3-è½»é‡ç‰ˆï¼‰â­ æ¨è",
    ),
]


def build_train_config(
    variant: VariantConfig,
    args: argparse.Namespace,
    batch_size: int,
) -> Dict[str, Any]:
    """æ„å»º Ultralytics è®­ç»ƒå‚æ•°å­—å…¸ã€‚"""

    batch_size = max(1, batch_size)

    base = {
        "task": "detect",
        "mode": "train",
        "model": str(MODEL_DIR / variant.yaml_file),
        "data": DATA_CONFIG,
        "epochs": args.epochs,
        "batch": batch_size,
        "imgsz": args.imgsz,
        "patience": args.patience,
        "device": args.device,
        "workers": variant.workers,
        "amp": True,
        "cache": "ram",
        "rect": True,
        "optimizer": "AdamW",
        "lr0": variant.lr0,
        "lrf": 0.0015,
        "momentum": 0.94,
        "weight_decay": 0.00045,
        "warmup_epochs": 3.0,
        "warmup_momentum": 0.8,
        "warmup_bias_lr": 0.1,
        "cos_lr": True,
        "hsv_h": 0.015,
        "hsv_s": 0.65,
        "hsv_v": 0.4,
        "degrees": 0.0,
        "translate": 0.1,
        "scale": 0.5,
        "shear": 0.0,
        "perspective": 0.0,
        "flipud": 0.0,
        "fliplr": 0.5,
        "mosaic": 0.0,
        "mixup": 0.0,
        "copy_paste": 0.0,
        "box": 7.5,
        "cls": 0.55,
        "dfl": 1.5,
        "val": True,
        "conf": 0.25,
        "iou": 0.7,
        "max_det": 400,
        "save": True,
        "save_period": args.save_period,
        "project": args.project,
        "name": f"{variant.key}_{args.tag}_bs{batch_size}",
        "exist_ok": True,
        "verbose": True,
        "seed": args.seed,
        "deterministic": False,
        "plots": True,
        "close_mosaic": 10,
        "overlap_mask": True,
        "mask_ratio": 4,
        "profile": False,
        "half": False,
        "dnn": False,
    }
    return base


def extract_metrics(results: Any) -> Dict[str, float]:
    """ä» Ultralytics ç»“æœå¯¹è±¡ä¸­æå–å¸¸ç”¨æŒ‡æ ‡ã€‚"""

    metrics = {}
    candidates = []

    if results is None:
        return metrics
    if hasattr(results, "metrics") and isinstance(results.metrics, dict):
        candidates.append(results.metrics)
    if hasattr(results, "results_dict") and isinstance(results.results_dict, dict):
        candidates.append(results.results_dict)
    if hasattr(results, "__dict__"):
        raw_dict = {k: v for k, v in vars(results).items() if isinstance(v, dict)}
        candidates.extend(raw_dict.values())

    for data in candidates:
        for key, value in data.items():
            if isinstance(value, (int, float)):
                metrics[key] = float(value)
    return metrics


def pick_metric(metrics: Dict[str, float], keys) -> Optional[float]:
    """æŒ‰ç…§ä¼˜å…ˆçº§è¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨æŒ‡æ ‡ã€‚"""

    for key in keys:
        if key in metrics:
            return metrics[key]
    return None


def run_variant(variant: VariantConfig, args: argparse.Namespace) -> Dict[str, float]:
    """è®­ç»ƒå•ä¸ªå˜ä½“å¹¶è¿”å›æŒ‡æ ‡ã€‚"""

    base_batch = args.batch if args.batch is not None else variant.batch
    attempt_batch = max(1, int(round(base_batch * args.batch_scale)))
    min_batch = max(1, args.min_batch)
    
    # æå‰åˆ›å»ºæƒé‡ç›®å½•é¿å…ä¿å­˜å¤±è´¥
    weights_root = Path(args.project) / f"{variant.key}_{args.tag}_bs{attempt_batch}"
    (weights_root / "weights").mkdir(parents=True, exist_ok=True)

    while True:
        train_cfg = build_train_config(variant, args, batch_size=attempt_batch)
        print("=" * 80)
        print(f"ğŸ¯ è®­ç»ƒ {variant.label}")
        print(f"ğŸ“ YAML: {train_cfg['model']}")
        print(f"ğŸ“¦ é¡¹ç›®: {train_cfg['project']} / {train_cfg['name']}")
        print(f"ğŸ§® Batch Size: {train_cfg['batch']} (min {min_batch})")

        model: Optional[RTDETR] = None
        try:
            model = RTDETR(train_cfg["model"])
            results = model.train(**{k: v for k, v in train_cfg.items() if k != "model"})
            metrics = extract_metrics(results)
            return metrics
        except RuntimeError as exc:
            message = str(exc).lower()
            if "invalid argument" in message:
                print("âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„æ•°æ®æˆ–æ•°å€¼å¼‚å¸¸ï¼Œå¯å°è¯•å¼€å¯ CUDA_LAUNCH_BLOCKING=1 å¹¶æ£€æŸ¥æ ‡ç­¾ã€‚")
            if "out of memory" in message and attempt_batch > min_batch:
                attempt_batch = max(min_batch, max(1, attempt_batch // 2))
                print(f"âš ï¸ æ˜¾å­˜ä¸è¶³ï¼Œé™è‡³ batch={attempt_batch} åé‡è¯•...")
                continue
            raise
        finally:
            if model is not None:
                del model
            torch.cuda.empty_cache()
            gc.collect()


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="è®­ç»ƒå¹¶å¯¹æ¯” RT-DETR å››ä¸ªå˜ä½“")
    parser.add_argument("--epochs", type=int, default=120, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--imgsz", type=int, default=640, help="è¾“å…¥åˆ†è¾¨ç‡")
    parser.add_argument("--patience", type=int, default=25, help="æ—©åœè€å¿ƒå€¼")
    parser.add_argument("--device", default="0", help="è®­ç»ƒä½¿ç”¨çš„è®¾å¤‡æ ‡è¯†")
    parser.add_argument("--project", default=DEFAULT_PROJECT, help="Ultralytics ç»“æœè¾“å‡ºç›®å½•")
    parser.add_argument("--tag", default="single", help="run åç§°åç¼€")
    parser.add_argument("--save-period", dest="save_period", type=int, default=20, help="æ£€æŸ¥ç‚¹ä¿å­˜é—´éš” (epoch)")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument(
        "--batch",
        type=int,
        help="è¦†ç›–é»˜è®¤ batch å¤§å°",
    )
    parser.add_argument(
        "--batch-scale",
        type=float,
        default=1.0,
        help="åœ¨é»˜è®¤/è‡ªå®šä¹‰ batch åŸºç¡€ä¸Šä¹˜ä»¥è¯¥ç³»æ•°",
    )
    parser.add_argument(
        "--min-batch",
        type=int,
        default=2,
        help="è‡ªåŠ¨é€€é¿æ—¶å…è®¸çš„æœ€å° batch",
    )
    parser.add_argument(
        "--variant",
        choices=[v.key for v in VARIANTS],
        help="å¯é€‰è¦†ç›–è„šæœ¬å†…çš„ SELECTED_VARIANT_KEY",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    
    variant_key = args.variant or SELECTED_VARIANT_KEY
    variant = next((v for v in VARIANTS if v.key == variant_key), None)
    if variant is None:
        raise SystemExit(
            f"æœªæ‰¾åˆ°è¦è®­ç»ƒçš„æ¨¡å‹: {variant_key}ï¼Œå¯é€‰: {[v.key for v in VARIANTS]}"
        )

    # torch.autograd.set_detect_anomaly(True)  # ç¦ç”¨å¼‚å¸¸æ£€æµ‹ä»¥é¿å…æ¢¯åº¦è®¡ç®—å¼‚å¸¸ä¸­æ–­è®­ç»ƒ
    
    print(f"\nğŸ§­ å½“å‰è®­ç»ƒæ¨¡å‹: {variant.label} ({variant_key})")
    print(f"ğŸ“ é…ç½®: batch={args.batch or variant.batch}, lr0={variant.lr0}, workers={variant.workers}")
    print("=" * 80)

    metrics = run_variant(variant, args)
    print(f"\nğŸ“Š {variant.label} æŒ‡æ ‡: {json.dumps(metrics, ensure_ascii=False, indent=2)}")

    if metrics:
        output_dir = Path(args.project) / "analysis"
        output_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = output_dir / f"{variant.key}_{args.tag}_{timestamp}.json"
        with report_path.open("w", encoding="utf-8") as f:
            json.dump(
                {
                    "timestamp": datetime.now().isoformat(),
                    "variant": variant.label,
                    "metrics": metrics,
                },
                f,
                indent=2,
                ensure_ascii=False,
            )
        print(f"ğŸ“„ è®­ç»ƒæŒ‡æ ‡å·²ä¿å­˜è‡³: {report_path}")


if __name__ == "__main__":
    torch.backends.cudnn.benchmark = True
    main()
