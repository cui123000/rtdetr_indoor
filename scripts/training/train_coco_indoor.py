#!/usr/bin/env python3
"""
COCO å®¤å†…å­æ•°æ®é›†è®­ç»ƒè„šæœ¬
ä½¿ç”¨ç­›é€‰åçš„ COCO å®¤å†…åœºæ™¯æ•°æ®ï¼ˆé˜ˆå€¼30ï¼š3,015 train / 151 valï¼‰
æ”¯æŒ RT-DETR æ¨¡å‹è®­ç»ƒ
è¿‡æ»¤æ¡ä»¶ï¼šå¯¹è±¡æ•° > 30ï¼Œä¿ç•™75.4%æ•°æ®ï¼Œä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨
"""

import os
import sys
import torch
import gc
from pathlib import Path
import argparse
import time

# å…¨å±€æ¨¡å‹è®¾ç½® - åœ¨è¿™é‡Œä¿®æ”¹è¦è®­ç»ƒçš„æ¨¡å‹
GLOBAL_MODEL = 'rtdetr-l'  # å¯é€‰: rtdetr-l, rtdetr-mnv4, rtdetr-mnv4-sea

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "ultralytics"))

def setup_environment():
    """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
    print("ğŸ”§ é…ç½®è®­ç»ƒç¯å¢ƒ...")
    
    # CUDAå†…å­˜ç®¡ç† - æœ€ä¼˜ç­–ç•¥ï¼šå…è®¸æ‰©å±•ä½†æ§åˆ¶ç¢ç‰‡
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512,garbage_collection_threshold:0.7,expandable_segments:True'
    os.environ['CUDA_LAUNCH_BLOCKING'] = '0'
    
    # PyTorchä¼˜åŒ–
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True
    
    # è®¾ç½®çº¿ç¨‹æ•°
    torch.set_num_threads(12)  # åŒ¹é…workersæ•°é‡
    os.environ['OMP_NUM_THREADS'] = '12'
    os.environ['MKL_NUM_THREADS'] = '12'
    
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()
        # ä¸é™åˆ¶æ˜¾å­˜ï¼Œè®©PyTorchè‡ªåŠ¨ç®¡ç†ï¼ˆä½ çš„GPUæ˜¾å­˜å……è¶³ï¼‰
        
        print(f"   âœ“ GPU: {torch.cuda.get_device_name(0)}")
        print(f"   âœ“ CUDA: {torch.version.cuda}")
        print(f"   âœ“ PyTorch: {torch.__version__}")
        print(f"   âœ“ æ˜¾å­˜ç®¡ç†: è‡ªåŠ¨ï¼ˆ24GB RTX 4090ï¼‰")
        print(f"   âœ“ Tensor Cores: å·²å¯ç”¨ (AMP + TF32)")
    else:
        print("   âš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦ä¼šå¾ˆæ…¢ï¼‰")

def get_model_config(model_name):
    """
    è·å–æ¨¡å‹é…ç½®
    
    å‚æ•°:
        model_name: æ¨¡å‹åç§°
            - rtdetr-l: RT-DETR-L å®˜æ–¹æ¨¡å‹
            - rtdetr-mnv4: RT-DETR with MobileNetV4 backbone
            - rtdetr-mnv4-sea: RT-DETR with MobileNetV4 + SEA attention
    """
    configs = {
        'rtdetr-l': {
            'pretrained': None,  # âŒ ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œä»é›¶è®­ç»ƒ
            'config_file': 'rtdetr-l.yaml',  # ä½¿ç”¨ YAML é…ç½®æ–‡ä»¶
            'batch': 4,  # é™ä½åˆ°4ä»¥é€‚é…é˜ˆå€¼30æ•°æ®é›†ï¼ˆ21.8G -> é¢„è®¡15Gï¼‰
            'lr0': 0.0015,
            'name': 'rtdetr_l_coco_indoor_scratch',  # ä¿®æ”¹åç§°æ ‡è¯†ä»é›¶è®­ç»ƒ
        },
        'rtdetr-mnv4': {
            'pretrained': None,  # âŒ ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œä»é›¶è®­ç»ƒ
            'config_file': 'rtdetr-mnv4-hybrid-m.yaml',
            'batch': 4,  # é™ä½åˆ°4ä»¥é€‚é…COCOå®¤å†…é«˜å¯†åº¦æ•°æ®ï¼ˆé˜ˆå€¼30ï¼Œ21.3Gâ†’é¢„è®¡14Gï¼‰
            'lr0': 0.0018,
            'name': 'rtdetr_mnv4_coco_indoor_scratch',  # ä¿®æ”¹åç§°æ ‡è¯†ä»é›¶è®­ç»ƒ
        },
        'rtdetr-mnv4-sea': {
            'pretrained': None,
            'config_file': 'rtdetr-mnv4-hybrid-m-sea.yaml',
            'batch': 4,  # å‚è€ƒvariants
            'lr0': 0.0015,
            'name': 'rtdetr_mnv4_sea_coco_indoor',
        },
    }
    
    if model_name not in configs:
        raise ValueError(
            f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}\n"
            f"å¯é€‰æ¨¡å‹: {', '.join(configs.keys())}"
        )
    
    return configs[model_name]

def get_training_config(model_cfg, args):
    """è·å–è®­ç»ƒé…ç½®"""
    
    # æ•°æ®é›†é…ç½® - 
    data_path = '/home/cui/rtdetr_indoor/datasets/coco_indoor_4k/coco_indoor_4k.yaml'
    
    # é¡¹ç›®è¾“å‡ºç›®å½•ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
    if not args.project.startswith('/'):
        project_path = str(project_root / args.project)
    else:
        project_path = args.project
    
    config = {
        'task': 'detect',
        'mode': 'train',
        'data': data_path,
        
        # åŸºç¡€è®­ç»ƒå‚æ•°
        'epochs': args.epochs,
        'batch': args.batch if args.batch > 0 else model_cfg['batch'],
        'imgsz': args.imgsz,
        'patience': 20,
        
        # è®¾å¤‡è®¾ç½® - å‚è€ƒ train_mnv4_variants.py çš„æˆåŠŸé…ç½®
        'device': args.device,
        'workers': 4,  # å’Œvariantsä¿æŒä¸€è‡´
        'amp': True,
        'cache': 'ram',  # é‡æ–°å¯ç”¨RAMç¼“å­˜ï¼ˆvariantsç”¨çš„ï¼‰
        'rect': True,  # ğŸ”¥ å…³é”®ï¼çŸ©å½¢è®­ç»ƒå¤§å¹…èŠ‚çœæ˜¾å­˜
        'single_cls': False,
        
        # ä¼˜åŒ–å™¨ - å‚è€ƒ train_mnv4_variants.py çš„é…ç½®
        'optimizer': 'AdamW',
        'lr0': model_cfg['lr0'],
        'lrf': 0.0015,  # å‚è€ƒ variants
        'momentum': 0.94,  # å‚è€ƒ variants
        'weight_decay': 0.00045,  # å‚è€ƒ variants
        'warmup_epochs': 3.0,
        'warmup_momentum': 0.8,
        'warmup_bias_lr': 0.1,
        'cos_lr': True,
        
        # æ•°æ®å¢å¼º - å‚è€ƒ train_mnv4_variants.pyï¼ˆå…³é—­ mosaicï¼‰
        'hsv_h': 0.015,
        'hsv_s': 0.65,  # å‚è€ƒ variants
        'hsv_v': 0.4,
        'degrees': 0.0,
        'translate': 0.1,
        'scale': 0.5,
        'shear': 0.0,
        'perspective': 0.0,
        'flipud': 0.0,
        'fliplr': 0.5,
        'mosaic': 0.0,  # å®Œå…¨å…³é—­ä»¥èŠ‚çœæ˜¾å­˜
        'mixup': 0.0,
        'copy_paste': 0.0,
        
        # æŸå¤±æƒé‡ - å‚è€ƒ train_mnv4_variants.py
        'box': 7.5,
        'cls': 0.55,  # å‚è€ƒ variants
        'dfl': 1.5,
        
        # éªŒè¯ - å‚è€ƒvariantsé…ç½®
        'val': True,
        'conf': 0.25,
        'iou': 0.7,
        'max_det': 400,  # æ¢å¤åˆ°variantsçš„å€¼
        
        # ä¿å­˜
        'save': True,
        'save_period': args.save_period,
        'project': project_path,
        'name': model_cfg['name'],
        'exist_ok': True,
        
        # å…¶ä»–
        'verbose': True,
        'seed': 42,
        'deterministic': False,
        'plots': True,
        'close_mosaic': 10,
    }
    
    return config

def train(args):
    """æ‰§è¡Œè®­ç»ƒ"""
    setup_environment()
    
    # ä½¿ç”¨å…¨å±€æ¨¡å‹æˆ–å‘½ä»¤è¡Œå‚æ•°
    model_name = args.model if args.model else GLOBAL_MODEL
    
    # è·å–æ¨¡å‹é…ç½®
    model_cfg = get_model_config(model_name)
    
    print("\n" + "="*70)
    print(f"ğŸ¯ è®­ç»ƒé…ç½®")
    print("="*70)
    print(f"æ¨¡å‹: {model_name}")
    print(f"æ¨¡å‹åç§°: {model_cfg['name']}")
    print(f"è®­ç»ƒæ–¹å¼: ä»é›¶è®­ç»ƒ (ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡)")
    print(f"æ•°æ®é›†: COCO å®¤å†…è¿‡æ»¤ç‰ˆ (3,015 train / 151 val)")
    print(f"è¿‡æ»¤æ¡ä»¶: å¯¹è±¡æ•° â‰¤ 30 (ç§»é™¤1,034å¼ é«˜å¯†åº¦å›¾ï¼Œä¿ç•™75.4%)")
    print(f"å¹³å‡å¯¹è±¡æ•°: ~20ä¸ª/å›¾ (vs åŸå§‹25.7ä¸ª)")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch if args.batch > 0 else model_cfg['batch']}")
    print(f"è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"å›¾åƒå°ºå¯¸: {args.imgsz}")
    print(f"å­¦ä¹ ç‡: {model_cfg['lr0']}")
    print("="*70 + "\n")
    
    # å¯¼å…¥ RT-DETR
    from ultralytics import RTDETR
    
    # åˆ¤æ–­æ˜¯ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿˜æ˜¯é…ç½®æ–‡ä»¶
    if model_cfg['pretrained']:
        print(f"ğŸ“¦ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_cfg['pretrained']}")
        model = RTDETR(model_cfg['pretrained'])
    elif model_cfg['config_file']:
        config_path = project_root / 'ultralytics' / 'ultralytics' / 'cfg' / 'models' / 'rt-detr' / model_cfg['config_file']
        if not config_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        print(f"ğŸ“„ ä½¿ç”¨é…ç½®æ–‡ä»¶: {model_cfg['config_file']}")
        model = RTDETR(str(config_path))
    else:
        raise ValueError("æ¨¡å‹é…ç½®é”™è¯¯ï¼šå¿…é¡»æŒ‡å®š pretrained æˆ– config_file")
    
    # è·å–è®­ç»ƒé…ç½®
    train_config = get_training_config(model_cfg, args)
    
    # æ·»åŠ æ˜¾å­˜æ¸…ç†å›è°ƒï¼ˆUltralyticsæ­£ç¡®æ–¹å¼ï¼‰
    batch_counter = {'count': 0}  # ä½¿ç”¨å­—å…¸ä¿æŒå¯å˜å¼•ç”¨
    
    def on_train_batch_end(trainer):
        """æ¯100ä¸ªbatchæ¸…ç†ä¸€æ¬¡æ˜¾å­˜"""
        batch_counter['count'] += 1
        if batch_counter['count'] % 100 == 0 and torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    def on_train_epoch_end(trainer):
        """æ¯ä¸ªepochç»“æŸæ¸…ç†æ˜¾å­˜ï¼Œä¸ºéªŒè¯è…¾å‡ºç©ºé—´"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
    
    def on_val_start(trainer):
        """éªŒè¯å¼€å§‹å‰å¼ºåˆ¶æ¸…ç†"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
    
    model.add_callback('on_train_batch_end', on_train_batch_end)
    model.add_callback('on_train_epoch_end', on_train_epoch_end)
    model.add_callback('on_val_start', on_val_start)
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    print(f"â° å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"âš ï¸  ä»é›¶è®­ç»ƒæ¨¡å¼: æ— é¢„è®­ç»ƒæƒé‡ï¼Œçº¯ç²¹å­¦ä¹ ")
    print(f"âœ… ä½¿ç”¨æˆåŠŸé…ç½®: rect=True, cache=ram, workers=4")
    print(f"ğŸ¯ æ•°æ®é›†ä¼˜åŒ–: è¿‡æ»¤äº†1,034å¼ é«˜å¯†åº¦å›¾(>30å¯¹è±¡)")
    print(f"ğŸ’¾ é¢„æœŸæ˜¾å­˜: 10-14G (batch={args.batch if args.batch > 0 else model_cfg['batch']})")
    print(f"âš¡ é¢„æœŸé€Ÿåº¦: ~2-3 it/s")
    print(f"ğŸ”„ ä¸‰é‡æ¸…ç†: epochç»“æŸã€éªŒè¯å¼€å§‹ã€æ¯100 batch")
    print(f"ğŸ“Š å…¬å¹³å¯¹æ¯”: L å’Œ MNV4 éƒ½ä»é›¶è®­ç»ƒï¼Œæ— é¢„è®­ç»ƒä¼˜åŠ¿\n")
    
    try:
        results = model.train(**train_config)
        
        print("\n" + "="*70)
        print("âœ… è®­ç»ƒå®Œæˆï¼")
        print("="*70)
        print(f"â° å®Œæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {train_config['project']}/{train_config['name']}")
        print("="*70)
        
        return results
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        # æ¸…ç†å†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()

def main():
    parser = argparse.ArgumentParser(description='COCO å®¤å†…å­æ•°æ®é›†è®­ç»ƒè„šæœ¬ (RT-DETR)')
    
    # æ¨¡å‹é€‰æ‹©ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€è®¾ç½®ï¼‰
    parser.add_argument('--model', type=str, default=None,
                       help=f'æ¨¡å‹åç§° (é»˜è®¤: {GLOBAL_MODEL}), å¯é€‰: rtdetr-l, rtdetr-mnv4, rtdetr-mnv4-sea')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=100,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch', type=int, default=-1,
                       help='æ‰¹æ¬¡å¤§å° (-1 ä½¿ç”¨é»˜è®¤å€¼)')
    parser.add_argument('--imgsz', type=int, default=640,
                       help='å›¾åƒå°ºå¯¸')
    parser.add_argument('--device', type=str, default='0',
                       help='è®­ç»ƒè®¾å¤‡ (å¦‚: 0, 0,1, cpu)')
    
    # ä¿å­˜è®¾ç½®
    parser.add_argument('--project', type=str, default='runs/detect',
                       help='é¡¹ç›®ä¿å­˜ç›®å½•')
    parser.add_argument('--save-period', type=int, default=10,
                       help='ä¿å­˜checkpointçš„é—´éš”è½®æ•°')
    
    args = parser.parse_args()
    
    # æ‰§è¡Œè®­ç»ƒ
    train(args)

if __name__ == '__main__':
    main()
