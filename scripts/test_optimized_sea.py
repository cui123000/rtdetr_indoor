#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–åçš„SEAæ³¨æ„åŠ›æ¨¡å—åœ¨RT-DETRä¸­çš„æ€§èƒ½è¡¨ç°
"""

import torch
import torch.nn as nn
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "ultralytics"))

def test_sea_variants():
    """æµ‹è¯•ä¸åŒSEAå˜ä½“çš„æ€§èƒ½"""
    print("ğŸ§ª æµ‹è¯•ä¼˜åŒ–åçš„SEAæ³¨æ„åŠ›æ¨¡å—...")
    
    try:
        from ultralytics.nn.modules.sea_attention import (
            Sea_Attention_Simplified,
            create_sea_attention
        )
        
        # ç®€åŒ–çš„æµ‹è¯•é…ç½® - åªæµ‹è¯•ç®€åŒ–ç‰ˆæœ¬
        test_configs = [
            (64, 32, 32, "Sea_Attention_Simplified", Sea_Attention_Simplified),
            (128, 40, 40, "Sea_Attention_Simplified", Sea_Attention_Simplified),
        ]
        
        batch_size = 2
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        results = {}
        
        for channels, H, W, variant_name, module_class in test_configs:
            print(f"\nğŸ“Š æµ‹è¯• {variant_name} - {channels}é€šé“, {H}x{W}")
            
            # åˆ›å»ºæ¨¡å—
            module = module_class(channels)
            module = module.to(device)
            module.eval()
            
            # åˆ›å»ºæµ‹è¯•è¾“å…¥
            x = torch.randn(batch_size, channels, H, W).to(device)
            
            # å‰å‘ä¼ æ’­æµ‹è¯•
            try:
                with torch.no_grad():
                    # é¢„çƒ­
                    for _ in range(3):
                        _ = module(x)
                    
                    # è®¡æ—¶æµ‹è¯•
                    torch.cuda.synchronize() if device.type == 'cuda' else None
                    start_time = time.time()
                    
                    for _ in range(10):
                        output = module(x)
                    
                    torch.cuda.synchronize() if device.type == 'cuda' else None
                    avg_time = (time.time() - start_time) / 10
                    
                    # æ£€æŸ¥è¾“å‡º
                    if torch.isnan(output).any():
                        print(f"  âŒ è¾“å‡ºåŒ…å« nan")
                        continue
                    
                    # è®¡ç®—å‚æ•°é‡
                    params = sum(p.numel() for p in module.parameters())
                    
                    results[variant_name] = {
                        'time_ms': avg_time * 1000,
                        'params': params,
                        'output_shape': output.shape,
                        'memory_mb': torch.cuda.max_memory_allocated() / 1024**2 if device.type == 'cuda' else 0
                    }
                    
                    print(f"  âœ… æˆåŠŸ - æ—¶é—´: {avg_time*1000:.2f}ms")
                    print(f"  ğŸ“¦ å‚æ•°é‡: {params:,}")
                    print(f"  ğŸ“ è¾“å‡ºå½¢çŠ¶: {output.shape}")
                    print(f"  ğŸ¯ è¾“å‡ºèŒƒå›´: [{output.min():.4f}, {output.max():.4f}]")
                    
            except Exception as e:
                print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
                continue
        
        # æ€§èƒ½æ€»ç»“
        if results:
            print("\nğŸ“ˆ æ€§èƒ½æ€»ç»“:")
            print("=" * 80)
            print(f"{'æ¨¡å—å':<25} {'æ—¶é—´(ms)':<10} {'å‚æ•°é‡':<12} {'å†…å­˜(MB)':<10} {'çŠ¶æ€'}")
            print("-" * 80)
            
            for variant_name, metrics in results.items():
                status = "âœ… ä¼˜ç§€" if metrics['time_ms'] < 50 else "âš ï¸ è¾ƒæ…¢" if metrics['time_ms'] < 100 else "âŒ æ…¢"
                print(f"{variant_name:<25} {metrics['time_ms']:<10.2f} {metrics['params']:<12,} "
                      f"{metrics['memory_mb']:<10.1f} {status}")
        
        return len(results) > 0
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_factory_function():
    """æµ‹è¯•å·¥å‚å‡½æ•°"""
    print("\nğŸ­ æµ‹è¯•SEAæ³¨æ„åŠ›å·¥å‚å‡½æ•°...")
    
    try:
        from ultralytics.nn.modules.sea_attention import create_sea_attention
        
        test_cases = [
            (64, 'simplified'),
            (128, 'simplified'),
        ]
        
        for dim, variant in test_cases:
            print(f"  ğŸ“‹ åˆ›å»º {variant} ç‰ˆæœ¬ (dim={dim})")
            module = create_sea_attention(dim, variant=variant, detection_mode=True)
            
            # ç®€å•å‰å‘æµ‹è¯•
            x = torch.randn(1, dim, 32, 32)
            with torch.no_grad():
                output = module(x)
            
            print(f"    âœ… è¾“å…¥: {x.shape} -> è¾“å‡º: {output.shape}")
            
        print("  ğŸ‰ å·¥å‚å‡½æ•°æµ‹è¯•å®Œæˆ!")
        return True
        
    except Exception as e:
        print(f"  âŒ å·¥å‚å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_detection_optimization():
    """æµ‹è¯•æ£€æµ‹ä¼˜åŒ–åŠŸèƒ½"""
    print("\nğŸ¯ æµ‹è¯•æ£€æµ‹ä¼˜åŒ–åŠŸèƒ½...")
    
    try:
        from ultralytics.nn.modules.sea_attention import Sea_Attention_Simplified
        
        # æµ‹è¯•ä¸åŒFPNå±‚çº§
        fpn_configs = [
            (64, 32, 32, "P3å±‚"),
            (128, 40, 40, "P4å±‚"), 
        ]
        
        for channels, H, W, layer_name in fpn_configs:
            print(f"  ğŸ“Š æµ‹è¯• {layer_name} - {channels}é€šé“, {H}x{W}")
            
            # åˆ›å»ºSEAæ¨¡å—
            sea_module = Sea_Attention_Simplified(channels)
            
            x = torch.randn(2, channels, H, W)
            
            with torch.no_grad():
                output = sea_module(x)
                
                print(f"    âœ… è¾“å‡ºå½¢çŠ¶: {output.shape}")
                print(f"    âœ… è¾“å‡ºèŒƒå›´: [{output.min():.4f}, {output.max():.4f}]")
        
        print("  ğŸ‰ æ£€æµ‹ä¼˜åŒ–æµ‹è¯•å®Œæˆ!")
        return True
        
    except Exception as e:
        print(f"  âŒ æ£€æµ‹ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("=" * 80)
    print("ğŸ¤– ä¼˜åŒ–SEAæ³¨æ„åŠ›æ¨¡å—æµ‹è¯• - RT-DETRæ£€æµ‹ä¸“ç”¨")
    print("=" * 80)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    
    # è¿è¡Œæµ‹è¯•
    test1 = test_sea_variants()
    test2 = test_factory_function()
    test3 = test_detection_optimization()
    
    if test1 and test2 and test3:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡! SEAæ¨¡å—ä¼˜åŒ–æˆåŠŸ")
        print("ğŸš€ å·²å‡†å¤‡å¥½é›†æˆåˆ°RT-DETRè®­ç»ƒä¸­")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥! éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
